expNumber: "1"
envName: "PandaReach-v2"   
total_timesteps: 20000
mode: True  
continueTraining: False                   
algorithm: "TQC"                    
policy: "MultiInputPolicy"   
ent_coef: 'auto'        
render: False
gamma: 0.95
learning_rate: 0.001
learning_starts: 10000
normalize: True   
batch_size: 512
n_envs: 1
testSamples: 10
verbose: 0       
#batch_size: 2048
buffer_size: 1000000
replay_buffer_kwargs : {'online_sampling' : True,
             'goal_selection_strategy' : 'future',
             'n_sampled_goal' : 4}

policy_kwargs : {'net_arch' : [128, 128], 
                 'n_critics' : 1}
save_freq: 10000

#modelSavePath: '/home/tumu/anaconda3/envs/stableBaselines/panda-gym/model'
modelSavePath: '/scratch/users/tbal21/.conda/envs/stableBaselines/panda-gym/modeltest'

logSavePath: '/scratch/users/tbal21/.conda/envs/stableBaselines/panda-gym/logtest'

#logSavePath: '/home/tumu/anaconda3/envs/stableBaselines/panda-gym/log'
pseudoI: False 
